# OpenCC

Automatic driving long tail / corner cases datasets

Corner cases (CC) are data that occur infrequently or represent a critical situation and are only available in datasets to a limited extent, if at all. However, for machine learning (ML), CC are important as they are required for training, verification, and improved performance of ML models during inference within automated driving systems.

![image](https://user-images.githubusercontent.com/29084184/179703750-38e921fb-1b0c-4a82-b7ea-c8f9f4fd42e3.png)

Real-World Object-Level Corner Cases

<!---
<img src="https://avs.auto/images/ui-controls.png">
-->
:book: <a href="./paper/"> <b>Corner cases (CC) papers</b> </a>

## Long-Tailed Recognition and Corner cases

While the natural data distribution contains head, tail, and open classes, existing classification approaches focus mostly on the head, the tail, often in a closed setting. Traditional deep learning models are good at capturing the big data of head classes; more recently, few-shot learning methods have been developed for the small data of tail classes.

<img width="447" alt="image" src="https://user-images.githubusercontent.com/29084184/179699597-f580c7e5-a98c-46e8-b6ce-ce8ab4e916a4.png">

[1]Ziwei Liu. [Large-Scale Long-Tailed Recognition in an Open World](https://github.com/Charmve/OpenCC/blob/main/paper/Liu_Large-Scale_Long-Tailed_Recognition_in_an_Open_World_CVPR_2019_paper.pdf). CVPR2019

<br>

## ğŸ Download

<img src="https://raw.githubusercontent.com/giandbt/synboost/master/display_images/three_anomaly_scenarios.png">

[[1](https://github.com/Charmve/OpenCC/blob/main/paper/Pixel-wise%20Anomaly%20Detection%20in%20Complex%20Driving%20Scenes.pdf)] Giancarlo Di Biase. Pixel-wise Anomaly Detection in Complex Driving Scenes. CVPR 2021

<img src="https://coda-dataset.github.io/assets/img/example.png">

[[2](https://coda-dataset.github.io/)] CODA: A Real-World Road Corner Case Dataset for Object Detection in Autonomous Driving

CODAæ•°æ®é›†ä¸»è¦æ˜¯ä»3ä¸ªç›®æ ‡æ£€æµ‹æ•°æ®é›†ä¸­æå–æ„å»ºçš„ï¼ŒåŒ…æ‹¬KITTIã€nuScenesã€ONCEã€‚ä»è¿™äº›å…¬å¼€æ•°æ®é›†ä¸­é€‰å–äº†1500ä¸ªåœºæ™¯å›¾ç‰‡ï¼ŒåŒ…å«çº¦6000ä¸ªç›®æ ‡çº§åˆ«çš„corner caseï¼Œâ¬†ï¸ å¦‚ä¸Šå›¾æ‰€ç¤ºä¸ºè®ºæ–‡ä¸­å±•ç¤ºçš„corner caseæ ·ä¾‹.

**Open datasets:**

- https://coda-dataset.github.io/download.html
- https://once-for-auto-driving.github.io/download.html#downloads
- https://www.cityscapes-dataset.com/downloads
- https://github.com/waymo-research/waymo-open-dataset

<br>

## Corner cases in levels

<img align="right" src="./images/corner_cases_in_levels.png" width="343" title="Do what you like, and do it best!">

Automated driving has become a major topic of interest not only in the active research community but also in mainstream media reports. Visual perception of such intelligent vehicles has experienced large progress in the last decade thanks to advances in deep learning techniques but some challenges still remain. 

One such challenge is the detection of corner cases. They are unexpected and unknown situations that occur while driving. Conventional visual perception methods are often not able to detect them because corner cases have not been witnessed during training. Hence, their detection is highly safety-critical, and detection methods can be applied to vast amounts of collected data to select suitable training data. A reliable detection of corner cases will not only further automate the data selection procedure and increase safety in autonomous driving but can thereby also affect the public acceptance of the new technology in a positive manner. 

In this work[[2](https://github.com/Charmve/OpenCC/blob/main/paper/Corner%20Cases%20for%20Visual%20Perception%20in%20Automated%20Driving.pdf)], we continue a previous systematization of corner cases on different levels by an extended set of examples for each level. Moreover, we group detection approaches into different categories and link them with the corner case levels. Hence, we give directions to showcase specific corner cases and basic guidelines on how to technically detect them.

Systematization of corner cases on different levels as given in [1]. The theoretical complexity of the detection typically increases from the bottom to the top.

<br>

<br>

## Some examples

<img src="./images/some-examples-in-levels.png">

**Scene 1**: A cyclist holds a stop sign in his hand. We donâ€™t know when his going to lift the sign. A driverless car must understand this scenario. Even if he raises the Stop Sign, the autopilot should not stop.

![Waymo - automatic driving long tail challenge (2019)](./images/scene-1.jpg)

**Scene 2**: The oncoming vehicles loaded with plastic pipes are scattered all over the place. The autopilot must learn to deal with this sudden situation and avoid their influence on the driverless vehicle.

![Waymo - automatic driving long tail challenge (2019)](./images/scene-2.jpg)

**Scene 3**: Due to road construction and other factors, the pavement is covered with cone barrels. The unmanned vehicle must recognize these scenes correctly and realize reasonable driving in the scene full of cone barrels on the road.

![Waymo - automatic driving long tail challenge (2019)](./images/scene-3.gif)

**Scene 4**: The traffic light is green, and the unmanned vehicle has the right of way. Although our unmanned vehicle arrives at the intersection first, it must give way to special vehicles(ambulance, etc) that will arrive later.

![Waymo - automatic driving long tail challenge (2019)](./images/scene-4.gif)

**Scene 5**: When there is a green light at the intersection, the unmanned vehicle is ready to turn left. When encountering the social vehicles running through the red light at high speed, the unmanned vehicle needs to identify this scene and stop in time to avoid the illegal vehicles.

![Waymo - automatic driving long tail challenge (2019)](./images/scene-5.gif)

**Scene 6**: A building facade reflecting cars. How does the machine â€œunderstandâ€ that the cars are behind you though you see them in front of you and accordingly instruct the self-driven car to reverse or move forward?

<table class="table table-striped table-bordered table-vcenter">
	<tr>
	  <td>
	  	<img src="./images/facade-reflecting-cars-1.jpg">
	  </td>
	  <td>
	  	<img src="./images/facade-reflecting-cars-2.jpg">
	  </td>
	</tr>
</table>

Fig2 A building facade reflecting cars


**Scene 7**: These scenarios are plenty. Here is one more illustration. How do you read this situationâ€¦ see figure 2 â€” is there a building (clock tower) in front of the vehicle or is the vehicle on a road in front of a tram?

<table class="table table-striped table-bordered table-vcenter">
	<tr>
	  <td>
	  	<img src="./images/tram-example-1.jpg">
	  </td>
	  <td>
	  	<img src="./images/tram-example-2.jpg">
	  </td>
	  <td>
	  	<img src="./images/tram-example-3.jpg">
	  </td>
	</tr>
</table>

Fig3 Tram Example (Figure 1,2,3)

**Scene 8**: Traffic Lights

<img src="./images/IMG_5256.JPG">

åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œçº¢ç»¿ç¯æ„ŸçŸ¥æ¨¡å—é€šå¸¸ä¼šè¢«å½“åšä¸€ä¸ªå•ç‹¬çš„å­æ¨¡å—è¿›è¡Œå•ç‹¬è®¾è®¡ï¼Œæœ¬æ–‡é’ˆå¯¹çº¢ç»¿ç¯æ„ŸçŸ¥è¿‡ç¨‹ä¸­å­˜åœ¨çš„éƒ¨åˆ†é—®é¢˜è¿›è¡Œæ±‡æ€»ï¼Œä»¥è¾¾åˆ°å…±åŒè®¨è®ºï¼Œå…±åŒè§£å†³è¡Œä¸šéš¾ç‚¹é—®é¢˜çš„ç›®æ ‡ã€‚

**1. å›¾åƒè¯†åˆ«é—®é¢˜æ±‡æ€»**

ã€corner case1ã€‘æ•…éšœç¯è¯†åˆ«ï¼ˆé•¿æ—¶é—´é»‘ç¯ï¼Œé•¿æ—¶é—´é»„ç¯é—ªçƒï¼‰ï¼Œè¿œè·ç¦»å®¹æ˜“è¯†åˆ«é”™è¯¯é—®é¢˜

ã€corner case2ã€‘é—ªçƒçŠ¶æ€è¯†åˆ«ï¼ˆçº¢ç¯é—ªçƒï¼Œé»„ç¯é—ªçƒï¼Œç»¿ç¯é—ªçƒï¼‰

ã€corner case3ã€‘è¿œè·ç¦»æ¡ä»¶ä¸‹ï¼Œå°ç›®æ ‡çº¢ç»¿ç¯è¯†åˆ«ï¼ˆé«˜é€Ÿ120km/hä¸‹ï¼Œè‡³å°‘è¦çœ‹åˆ°200mè¿œï¼‰

ã€corner case4ã€‘å¤ªé˜³å…‰å¹²æ‰°ï¼ˆé€†å…‰ã€å…‰ç…§ä¸è¶³å¯¼è‡´å›¾åƒç¯ç›˜é¢œè‰²è¿‡æµ…ï¼Œè¿‘ä¼¼é»‘ç¯ï¼‰

ã€corner case5ã€‘æŠ“æ‹ç¯å¹²æ‰°ï¼ˆå¤œé—´æŠ“æ‹ç¯è¿‡äº®ï¼Œå¯¼è‡´å›¾åƒè¿‡æ›ï¼Œå›¾åƒç¯ç›˜æ— æ³•åˆ†åˆ«è½®å»“è¾¹ç•Œï¼‰

ã€corner case6ã€‘é•œå¤´å—åˆ°æ±¡æ¸å¹²æ‰°ï¼ˆå¤œé—´æŠ“æ‹ç¯è¿‡äº®ï¼Œå¯¼è‡´å›¾åƒè¿‡æ›ï¼Œå›¾åƒç¯ç›˜æ— æ³•åˆ†åˆ«è½®å»“è¾¹ç•Œï¼›é›¨é›ªé®æŒ¡é•œå¤´å¯¼è‡´æ— æ³•æŠ“æ‹åˆ°æ˜“è¯†åˆ«çš„å›¾åƒç™»ï¼‰

ã€corner case7ã€‘é€‚é…å„å¼å„æ ·çš„äº¤é€šç¯æ£€æµ‹è¯†åˆ«ï¼ˆç«–æ¡ç¯<å¸¸è§>ï¼Œæ¨ªæ¡ç¯<å¸¸è§>ï¼Œä¸´æ—¶ç«–ç¯ï¼Œè¯»æ¡æ¨ªç¯ï¼Œè¯»æ¡ç«–ç¯ï¼Œé«˜é€Ÿé€šé“ç¯ï¼ŒéæœºåŠ¨è½¦é“ç¯ï¼Œäººè¡Œæ¨ªé“ç¯ï¼Œå•ç»„ç¯ï¼Œä¸¤ç»„ç¯ï¼Œä¸‰ç»„ç¯ï¼Œå››ç»„ç¯ï¼Œç®­å¤´ç¯ï¼Œåœ†å¤´ç¯ç­‰ï¼‰

[1] è¯»æ¡ç«–ç¯

![image](https://user-images.githubusercontent.com/29084184/174219006-914baca2-c454-4126-bed8-c9de3f26b8ee.png)
![image](https://user-images.githubusercontent.com/29084184/174218955-d98a6d02-3ff7-430b-8af6-a86273ae80ba.png)
![image](https://user-images.githubusercontent.com/29084184/174218965-feb32cae-e288-47a8-99f8-e6e54b42caf3.png)


[2] è¯»æ¡æ¨ªç¯

![image](https://user-images.githubusercontent.com/29084184/174218712-1666678a-adb1-4ea1-92ce-01bd3c0a2887.png)
![image](https://user-images.githubusercontent.com/29084184/174218713-b47ddbca-aad0-45df-8f62-09c58ba679ac.png)

[3] ä¸‰ç®­å¤´ç¯

![image](https://user-images.githubusercontent.com/29084184/174218834-fb95c509-1fa0-439a-8a89-60fc052aa2ac.png)
![image](https://user-images.githubusercontent.com/29084184/174218841-8b7f7c91-316e-4467-b199-b08753a6b1ac.png)
![image](https://user-images.githubusercontent.com/29084184/174218853-d7f1d5ae-9237-4a84-bf36-d7a58ce2208b.png)


[4] å€’è®¡æ—¶ä¸ç¯ç›˜ä¸Š

![image](https://user-images.githubusercontent.com/29084184/174218868-9170cf6a-b3b3-41b5-a0c4-8ed9d759ecfa.png)
![image](https://user-images.githubusercontent.com/29084184/174218879-ec4959a4-ecf5-4a31-8f07-f55a15b034a2.png)
![image](https://user-images.githubusercontent.com/29084184/174218886-37dfb2f3-52d2-43bf-8bdd-1f75b53b1f01.png)


[5] å€’è®¡æ—¶åœ¨ç¯ç›˜ä¸€ä¾§ï¼ˆé€šå¸¸åœ¨ç¯ç›˜å³ä¾§ï¼‰

![image](https://user-images.githubusercontent.com/29084184/174218901-13e42c71-9b75-476d-9317-ed4ff6f00336.png)

ã€corner case8ã€‘äº¤é€šç¯èƒŒæ™¯å¹²æ‰°ï¼ˆå¸¸è§„èƒŒæ™¯ä¸ºå¤©ç©ºã€æ ‘æœ¨ï¼Œä¸å¸¸è§çš„èƒŒæ™¯åŒ…æ‹¬å„å¼å„æ ·çš„å»ºç­‘ç‰©ã€å¹¿å‘Šç‰ŒèƒŒæ™¯ï¼‰

ã€corner case9ã€‘LEDé—ªçƒé—®é¢˜ï¼ˆä¸€äº›ä¸åˆè§„çš„äº¤é€šç¯å­˜åœ¨LEDé—ªçƒï¼Œäººçœ¼çœ‹åˆ°ç¯æœ‰é¢œè‰²ï¼Œå›¾åƒæŠ“æ‹åˆ°çš„ä¸ºé»‘è‰²ï¼‰

ã€corner case10ã€‘åŠ¨æ€äº¤é€šç¯é—®é¢˜ï¼ˆéƒ¨åˆ†åŸå¸‚çš„éƒ¨åˆ†äº¤é€šç¯ï¼Œä¼šæ ¹æ®äº¤é€šæµæˆ–è€…æ–½å·¥æƒ…å†µè°ƒæ•´å¤šç»„ç¯ä¸­ç¯äº®çš„çŠ¶æ€ï¼Œä¾‹å¦‚ä¸¤ç»„ç¯ï¼Œä¸€ä¸ªå·¦è½¬ï¼Œä¸€ä¸ªç›´è¡Œç¯ï¼Œåœ¨æŸäº›æ—¶æ®µï¼Œåªè®©ä¸€ä¸ªç¯äº®ï¼Œå®¹æ˜“é€ æˆè§„æ§æ— æ³•å¯¹åº”äº¤é€šç¯è¿›è¡Œå†³ç­–ï¼Œå¯¼è‡´è¯¥åœè½¦ä¸åœï¼Œè¯¥å‰è¿›ä¸èµ°ç­‰é—®é¢˜ï¼‰

ã€corner case11ã€‘å€’è®¡æ—¶è¯†åˆ«é—®é¢˜ï¼ˆå€’è®¡æ—¶æ•°å­—ç‰Œå¾€å¾€æ›´å°ï¼Œè€Œä¸”å¸ƒå±€å„ä¸ç›¸åŒï¼Œé€šå¸¸å¸¸è§çš„å¸ƒå±€åŒ…æ‹¬ï¼Œå•ç‹¬å€’è®¡æ—¶ç‰Œ<ç«‹äºç«–ç¯å³ä¾§æˆ–å¤´é¡¶>ï¼Œä¸ç¯ç‰Œä¸€ä½“å€’è®¡æ—¶<ç«‹äºç¯ç›˜ä¸­é—´>ï¼›å€’è®¡æ—¶æ•°å­—ä¹Ÿä¸ç›¸åŒï¼Œé€šå¸¸æœ‰ä¸ªä½æ•°å­—å’Œä¸¤ä½æ•°å­—ï¼Œä¸¤ä½æ•°å­—å­˜åœ¨01ã€02...ï¼Œæœ€å¤§æ•°å­—å¯ä»¥åˆ°99ï¼›å¤œæ™šè¯†åˆ«å€’è®¡æ—¶ç‰Œå®¹æ˜“å—åˆ°å¤§å…‰æ™•å¹²æ‰°ï¼Œé€ æˆè‚‰çœ¼æ— æ³•è¯†åˆ«æ•°å­—ï¼›åœ¨è¾ƒè¿œåœ°æ–¹ï¼Œå€’è®¡æ—¶ç‰Œæ— æ³•è¯†åˆ«ç­‰é—®é¢˜ï¼‰

ã€corner case12ã€‘ç®­å¤´æŒ‡å‘ã€åœ†å¤´è¯†åˆ«é—®é¢˜ï¼ˆè¾ƒè¿œçš„åœ°æ–¹ï¼Œç®­å¤´ä¸åœ†å¤´ç±»å‹å®¹æ˜“æ··æ·†ï¼Œç®­å¤´æŒ‡å‘è¯†åˆ«å‡†ç¡®åº¦è¾ƒä½ç­‰é—®é¢˜ï¼‰

**2. ä¾èµ–é«˜ç²¾åœ°å›¾è¯†åˆ«çº¢ç»¿ç¯é—®é¢˜æ±‡æ€»**

ã€corner case1ã€‘å¤šé¢—æ‘„åƒå¤´åˆ‡æ¢é€‰æ‹©é—®é¢˜ã€‚è‡ªåŠ¨é©¾é©¶ä¸­é€šå¸¸è‡³å°‘éœ€è¦ä¸¤é¢—æ‘„åƒå¤´(è¿œ/è¿‘ç„¦è·)æ¥å®Œæˆçº¢ç»¿ç¯å›¾åƒé‡‡é›†é—®é¢˜ï¼Œä½†ä¾èµ–é«˜ç²¾åœ°å›¾æ–¹æ¡ˆä¸­ï¼Œæœ€ç»ˆåªä¼šé€‰æ‹©ä¸€å¼ å›¾åƒå®Œæˆæ£€æµ‹è¯†åˆ«è¿‡ç¨‹ï¼Œç²¾ç¡®çš„é€‰æ‹©å“ªä¸€å¼ å›¾åƒæ¥å®Œæˆåç»­è¿‡ç¨‹éœ€è¦åœ¨å¤§é‡çš„è¯•ç”¨è¿‡ç¨‹ä¸­ä¸æ–­è°ƒä¼˜ï¼Œä»è€Œé€‚é…å„å¼å„æ ·çš„åœºæ™¯ã€‚

ã€corner case2ã€‘å·¦è½¬å¾…è½¬åŒºé‡‡ç”¨å³å‰ä¾§å®½è§†è§’æ‘„åƒå¤´å›¾åƒï¼Œå½“å·¦è½¬å¾…è½¬åŒºè·ç¦»ç›´è¡Œäº¤é€šç¯è¾ƒè¿œæ—¶ï¼Œå­˜åœ¨å³å‰ä¾§æ‘„åƒå¤´æˆåƒæ— æ³•åŒºåˆ†çº¢ç»¿ç¯é¢œè‰²ï¼ˆå³çº¢ç»¿ç¯åœ¨å›¾åƒä¸Šæ— è®ºæ˜¯çº¢ã€é»„ã€ç»¿å“ªç§é¢œè‰²ï¼Œè‚‰çœ¼çœ‹éƒ½æ˜¯é»‘è‰²ï¼‰

ã€corner case3ã€‘å·¦è½¬å¾…è½¬åŒºé‡‡ç”¨å³å‰ä¾§å®½è§†è§’æ‘„åƒå¤´å›¾åƒï¼Œå½“å·¦è½¬å¾…è½¬åŒºè·ç¦»ç›´è¡Œäº¤é€šç¯è¾ƒè¿œæ—¶ï¼Œå€’è®¡æ—¶åŠŸèƒ½æ— æ³•æ­£å¸¸ä½¿ç”¨ï¼Œäººçœ¼æ— æ³•ä»å›¾åƒä¸­åŒºåˆ†æ•°å­—

ã€corner case4ã€‘é«˜ç²¾åœ°å›¾ä¸­æ˜¯æŒ‰ç…§è½¦é“çº¿lane idä¸äº¤é€šç¯signal idä¸€ä¸€å¯¹åº”ç»‘å®šï¼Œç”±äºæ£€æµ‹æ¨¡å‹ä¼šæœç´¢åˆ°æ„Ÿå…´è¶£åŒºåŸŸä¸­çš„å…¨éƒ¨è¿‘ä¼¼çº¢ç»¿ç¯ç¯æ¡†ï¼Œè¿›è€Œå†ä¸é«˜ç²¾åœ°å›¾é€šè¿‡ä½ç½®ç›¸è¿‘è®¡ç®—è¿›è¡ŒåŒ¹é…ã€‚å› æ­¤åœ¨ç›´è¡Œé“è·¯ï¼Œå·¦è½¬å¾…è½¬é“è·¯ç­‰éœ€è¦ç»‘å®šçº¢ç»¿ç¯çš„åœºæ™¯ä¸­ï¼Œåœ°å›¾ä¸­éœ€è¦å°†å…¨éƒ¨äº¤é€šç¯è¿›è¡Œç»‘å®šã€‚ç”±äºé«˜ç²¾åœ°å›¾ä¸­ç»‘ç¯æ˜¯äººå·¥å®Œæˆçš„ï¼Œå¾€å¾€å®¹æ˜“å‡ºç°åˆ¶å›¾ä¸­é’ˆå¯¹åºŸç¯(ä¸äº®ï¼Œä¸€ç›´ä¸ºé»‘ç¯)å®¹æ˜“å‡ºç°å¿˜è®°ç»‘å®šé—®é¢˜ï¼Œæœ€ç»ˆå¯¼è‡´åŒ¹é…æ—¶ï¼Œå¯èƒ½å‡ºç°åŒ¹é…é”™è¯¯é—®é¢˜

ã€corner case5ã€‘é«˜ç²¾åœ°å›¾ä¸­å­˜åœ¨å•lane idç»‘å®šå¤šsignal idé—®é¢˜ï¼Œè§„åˆ™çš„ä¸ä¸€è‡´æ€§å®¹æ˜“å¯¼è‡´åŒ¹é…é—®é¢˜

ã€corner case6ã€‘é«˜ç²¾åœ°å›¾ä¸­ç”±äºæœ€ç»ˆç»‘å®šsignal idçš„lane idå¾€å¾€æ¯”è¾ƒçŸ­ï¼Œä½†æ˜¯ç°å®æƒ…å†µè¦æ±‚è‡ªåŠ¨é©¾é©¶è½¦è¾†éœ€è¦åœ¨éå¸¸è¿œå¤„èƒ½å¤Ÿçœ‹åˆ°äº¤é€šç¯ï¼Œå› æ­¤éœ€è¦é€šè¿‡å¯¹åœ°å›¾ä¸­lane idåç»§è½¦é“çº¿è¿›è¡ŒæŸ¥è¯¢ï¼Œå¹¶ä¸”ç¡®è®¤åç»§è½¦é“çº¿æ˜¯å¦ç»‘å®šçº¢ç»¿ç¯ï¼Œè€Œæœ€ç»ˆæ¨å¯¼å‡º100ç±³ç”šè‡³æ˜¯200ç±³è¿œçš„è·ç¦»ä¸­æ˜¯å¦å­˜åœ¨çº¢ç»¿ç¯ï¼Œè¿›è€Œå†³å®šæ˜¯å¦å¼€å¯äº¤é€šç¯è¯†åˆ«åŠŸèƒ½

ã€corner case7ã€‘åœ¨è‡ªåŠ¨é©¾é©¶æ±½è½¦è¶Šè¿‡åœæ­¢çº¿åï¼Œè‡ªè½¦æ‰€å¤„çš„lane idä¹Ÿä¼šéšä¹‹æ”¹å˜ï¼Œä½†è¿™ä¸ªæ—¶å€™æ±½è½¦éœ€è¦ç»§ç»­è§‚æµ‹äº¤é€šç¯ï¼Œæ¥è¾…åŠ©è½¦è¾†ä¸é—¯çº¢ç¯ï¼Œå› æ­¤éœ€è¦å¯¹ä¹‹å‰çš„lane idè¿›è¡ŒæŸ¥è¯¢ã€‚é€šå¸¸è¦è·å–ä¹‹å‰çš„lane idæœ‰ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§æ˜¯çŸ­æš‚è®°å¿†åˆšåˆšç»è¿‡çš„lane id(ç»‘ç¯)ï¼Œä¸€ç§æ˜¯è®¾è®¡å‰ç»§æŸ¥è¯¢lane id(ç»‘ç¯)

ã€corner case8ã€‘å·¦è½¬å¾…è½¬åŒºåœæ­¢çº¿å‰æ–¹æœ‰ä¸“é—¨çš„å·¦è½¬äº¤é€šç¯ï¼Œè¿›å…¥å·¦è½¬å¾…è½¬åŒºå‰æ­£å‰æ–¹æœ‰å·¦è½¬ç¯å’Œç›´è¡Œç¯ï¼Œå½“å‰è·¯å£ç›¸å½“äºæœ‰ä¸¤ç»„ç¯ï¼Œä¸€ç»„ä¸ºå•ç‹¬çš„ä¸“é—¨è¾…åŠ©çš„å·¦è½¬äº¤é€šç¯ï¼Œä¸€ç»„ä¸ºç›´è¡Œ+å·¦è½¬ç¯ã€‚

**Scene 9**: äº¤é€šæ ‡è¯†ç‰Œ

<img src="./images/IMG_5255.JPG">

<!--   template jpg --
<table class="table table-striped table-bordered table-vcenter">
	<tr>
	  <td>
	  	<img src="./images/car-in-car-1.jpg">
	  </td>
	  <td>
	  	<img src="./images/car-in-car-2.jpg">
	  </td>
	</tr>
</table>
-->

## What is it and how to address? 

- Tweak model

Increase threshold in existing model: There is a confidence level associated with every object (which is here plotted for your understanding). A straightforward way would be to increase the threshold. In the tram example when I do that the building (clock) goes away (Figure 3). Great, this solves the problem. We have to be careful here to double check if we are losing any crucial information. The below typical street scene will illustrate this aspect. Like in the tram example here too we detect objects (pedestrians) in the puddle and more critically we detect a traffic light in the reflection which will confuse the machine in the vehicle.

<table class="table table-striped table-bordered table-vcenter">
	<tr>
	  <td>
	  	<img src="./images/threshold-1.jpg">
	  </td>
	  <td>
	  	<img src="./images/threshold-2.jpg">
	  </td>
	</tr>
</table>

We can increase the threshold but as can be seen below while the reflected pedestrian goes away we also miss some crucial information like the actual traffic light, the vehicle at a distance and a few pedestrians that are not identified. Increasing threshold is a strategy but beware of this risk

<img src="./images/threshold-3.jpg">

- GAN - Generative Adversarial Networks

https://user-images.githubusercontent.com/29084184/179702066-9e27f1fc-7251-4d9d-8f6f-cf12e2262cec.mp4

[[4](https://openaccess.thecvf.com/content_CVPR_2019/papers/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.pdf)] Tero Karras, Samuli Laine. A Style-Based Generator Architecture for Generative Adversarial Networks. CVPR2019

- Others
	- expert system 

	- inverse reinfocement learning

	- data-driven perception-prediction mutil-task model training in large scale

ï¼ˆæ•°æ®é©±åŠ¨çš„è‡ªåŠ¨é©¾é©¶ç®—æ³•æ¨¡å‹ã€BEVFormerã€å¤§æ¨¡å‹èåˆç›¸å…³è®ºæ–‡ï¼Œæ–‡ä»¶å¤ªå¤§ç§ä¿¡å‘ï¼‰

## äº¤æµç¾¤

> å®Œæ•´è®ºæ–‡åˆé›†ä¸‹è½½ï¼Œå…¬ä¼—å· **"è¿ˆå¾®AIç ”ä¹ ç¤¾"** åå°å›å¤â€œè‡ªåŠ¨é©¾é©¶æ•°æ®é©±åŠ¨è®ºæ–‡é›†â€å…³é”®å­—è·å–ã€‚

è‡ªåŠ¨é©¾é©¶æŠ€æœ¯å‚è€ƒäº¤æµç¾¤ï¼ˆçŸ¥è¯†æ˜Ÿçƒï¼‰æ¥äº†ï¼æƒ³è¦äº†è§£æœ€æ–°æœ€å¿«æœ€å¥½çš„è‡ªåŠ¨é©¾é©¶CV/DL/MLè®ºæ–‡é€Ÿé€’ã€è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¼˜åŒ–ã€å•†ä¸šåˆ†æã€ä¼˜è´¨å¼€æºé¡¹ç›®ã€å­¦ä¹ æ•™ç¨‹å’Œå®æˆ˜è®­ç»ƒç­‰èµ„æ–™ï¼Œæ¬¢è¿æ‰«æä¸‹æ–¹äºŒç»´ç ï¼ŒåŠ å…¥è‡ªåŠ¨é©¾é©¶æŠ€æœ¯äº¤æµç¾¤ï¼Œå·²æ±‡é›†æ•°åƒäººï¼

<div align="center">
<img src="./images/48848415251258T2.JPG" width="360">

<h5>æ‰«æåŠ å…¥äº¤æµç¾¤</h5>
</div>

## Reference

- https://developpaper.com/waymo-automatic-driving-long-tail-challenge-2019/
- https://harshaangeri.medium.com/mirror-mirror-on-the-wall-ai-deep-learning-needs-to-learn-it-all-ad221bd399e1
- https://zhuanlan.zhihu.com/p/401235846
- https://github.com/PointsCoder/ONCE_Benchmark


## é‡è¦å‚è€ƒæ–‡çŒ®

[1] â€œSystematization of Corner Cases for Visual Perception in Automated Driving,â€ IV, Las Vegas, USA, 2020.

[2] â€œTowards Corner Case Detection by Modeling the Uncertainty of Instance Segmentation Networks,â€ in Proc. of ICPR, Workshop, Milan, Italy, 2021.

[3] "An Application-Driven Conceptualization of Corner Cases for Perception in Highly Automated Driving". Florian Heidecker, CVPR 2021. https://arxiv.org/pdf/2103.03678.pdf

[4] "Pixel-wise Anomaly Detection in Complex Driving Scenes". Giancarlo Di Biase. CVPR 2021. https://arxiv.org/pdf/2103.05445.pdf. https://github.com/giandbt/synboost. https://github.com/tianyu0207/PEBAL

[5] â€œCorner Cases for Visual Perception in Automated Driving: Some Guidance on Detection Approaches,â€ arXiv:2102.05897, 2021.

[6] â€œOpen-Set Radar Waveform Classification:Comparison of Different Features and Classifiers,â€ IEEE International Radar Conference, Washington DC, 2020.

[7] â€œEntropy Maximization and Meta Classification for Out-of-Distribution Detection in Semantic Segmentation,â€ arXiv:2012.06575, 2020.

